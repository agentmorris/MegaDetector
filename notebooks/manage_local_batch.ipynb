{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f27086",
   "metadata": {},
   "source": [
    "# Managing a local MegaDetector batch\n",
    "\n",
    "This notebook represents an interactive process for running MegaDetector and SpeciesNet on large batches of images, including typical and optional postprocessing steps.  Everything after \"Merge results...\" is basically optional, and we typically do a mix of these optional steps, depending on the job.\n",
    "\n",
    "This notebook is auto-generated from manage_local_batch.py (a cell-delimited .py file that is used the same way, typically in Spyder or VS Code).\n",
    "\n",
    " Semi-automated process for managing a local MegaDetector (and, optionally, SpeciesNet job,\n",
    " including standard postprocessing steps.\n",
    "\n",
    "\n",
    " This script is not intended to be run from top to bottom like a typical Python script,\n",
    " it's a notebook disguised with a .py extension.  It's the Bestest Most Awesome way to\n",
    " run MegaDetector, but it's also pretty complex; if you want to play with this, you might\n",
    " want to check in with cameratraps@lila.science for some tips.  Otherwise... YMMV.\n",
    "\n",
    "\n",
    " Some general notes on using this script, which I run in Spyder, though everything will be\n",
    " the same if you are reading this in Jupyter Notebook (using the .ipynb version of the \n",
    " script):\n",
    "\n",
    "\n",
    " * Typically when I have a MegaDetector job to run, I make a copy of this script.  Let's \n",
    "   say I'm running a job for an organization called \"bibblebop\"; I have a big folder of\n",
    "   job-specific copies of this script, and I might save a new one called \"bibblebop-2023-07-26.py\" \n",
    "   (the filename doesn't matter, it just helps me keep these organized).\n",
    "\n",
    "\n",
    " * There are three variables you need to set in this script before you start running code:\n",
    "   \"input_path\", \"organization_name_short\", and \"job_date\".  You will get a sensible error if you forget \n",
    "   to set any of these.  In this case I might set those to \"/data/bibblebobcamerastuff\",\n",
    "   \"bibblebop\", and \"2023-07-26\", respectively.\n",
    "\n",
    "\n",
    " * The defaults assume you want to split the job into two tasks (this is the default because I have \n",
    "   two GPUs).  Nothing bad will happen if you do this on a zero-GPU or single-GPU machine, but if you\n",
    "   want everything to run in one logical task, change \"n_gpus\" and \"n_jobs\" to 1 (instead of 2).\n",
    "\n",
    "\n",
    " * After setting the required variables, I run the first few cells - up to and including the one \n",
    "   called \"Generate commands\" - which collectively take basically zero seconds.  After you run the\n",
    "   \"Generate commands\" cell, you will have a folder that looks something like:\n",
    "\n",
    "\n",
    "     ~/postprocessing/bibblebop/bibblebop-2023-07-06-mdv5a/\n",
    "\n",
    "\n",
    "   On Windows, this means:\n",
    "\n",
    "\n",
    "     ~/postprocessing/bibblebop/bibblebop-2023-07-06-mdv5a/\n",
    "\n",
    "\n",
    "   Everything related to this job - scripts, outputs, intermediate stuff - will be in this folder.\n",
    "   Specifically, after the \"Generate commands\" cell, you'll have scripts in that folder called something\n",
    "   like:\n",
    "\n",
    "\n",
    "   run_chunk_000_gpu_00.sh (or .bat on Windows)\n",
    "\n",
    "\n",
    "   Personally, I like to run that script directly in a command prompt (I just leave Spyder open, though \n",
    "   it's OK if Spyder gets shut down while MD is running).\n",
    "\n",
    "\n",
    "   At this point, once you get the hang of it, you've invested about zero seconds of human time,\n",
    "   but possibly several days of unattended compute time, depending on the size of your job.\n",
    "\n",
    "\n",
    " * Then when the jobs are done, back to the interactive environment!  I run the next few cells,\n",
    "   which make sure the job finished OK, and the cell called \"Post-processing (pre-RDE)\", which \n",
    "   generates an HTML preview of the results.  You are very plausibly done at this point, and can ignore\n",
    "   all the remaining cells.  If you want to do things like repeat detection elimination, or running \n",
    "   a classifier, or splitting your results file up in specialized ways, there are cells for all of those\n",
    "   things, but now you're in power-user territory, so I'm going to leave this guide here.  Email\n",
    "   cameratraps@lila.science with questions about the fancy stuff.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df3c28d",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import stat\n",
    "import time\n",
    "import re\n",
    "\n",
    "import humanfriendly\n",
    "import clipboard #noqa\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "from megadetector.utils.ct_utils import split_list_into_n_chunks\n",
    "from megadetector.utils.ct_utils import image_file_to_camera_folder\n",
    "from megadetector.utils.ct_utils import split_list_into_fixed_size_chunks\n",
    "\n",
    "from megadetector.detection.run_detector_batch import load_and_run_detector_batch\n",
    "from megadetector.detection.run_detector_batch import write_results_to_file\n",
    "from megadetector.detection.run_detector import DEFAULT_OUTPUT_CONFIDENCE_THRESHOLD\n",
    "from megadetector.detection.run_detector import estimate_md_images_per_second\n",
    "from megadetector.detection.run_detector import get_detector_version_from_model_file\n",
    "\n",
    "from megadetector.postprocessing.postprocess_batch_results import PostProcessingOptions\n",
    "from megadetector.postprocessing.postprocess_batch_results import process_batch_results\n",
    "\n",
    "from megadetector.utils.path_utils import insert_before_extension\n",
    "from megadetector.utils.path_utils import find_images\n",
    "from megadetector.utils.path_utils import path_join\n",
    "from megadetector.utils.path_utils import write_list_to_file\n",
    "from megadetector.utils.path_utils import open_file\n",
    "\n",
    "from megadetector.utils.wi_utils import generate_md_results_from_predictions_json\n",
    "from megadetector.utils.wi_utils import generate_instances_json_from_folder\n",
    "\n",
    "\n",
    "## Inference options\n",
    "\n",
    "# To specify a non-default confidence threshold for including detections in the .json file\n",
    "json_threshold = None\n",
    "\n",
    "# Turn warnings into errors if more than this many images are missing\n",
    "max_tolerable_failed_images = 100\n",
    "\n",
    "# Should we supply the --image_queue_option to run_detector_batch.py?  I only set this\n",
    "# when I have a very slow drive and a comparably fast GPU.  When this is enabled, checkpointing\n",
    "# is not supported within a job, so I set n_jobs to a large number (typically 100).\n",
    "use_image_queue = True\n",
    "\n",
    "# If we are using an image queue (worker pool), should that include image preprocessing\n",
    "# (as opposed to just image loading)?  Only relevant if use_image_queue is True.\n",
    "preprocess_on_image_queue = True\n",
    "\n",
    "# Number of image queue loader workers.  Only relevant if use_image_queue is True.\n",
    "image_queue_loader_workers = 4\n",
    "\n",
    "# Only relevant when we're using a single GPU\n",
    "default_gpu_number = 0\n",
    "\n",
    "# Should we supply --quiet to run_detector_batch.py?\n",
    "quiet_mode = True\n",
    "\n",
    "# Specify a target image size when running MD... strongly recommended to leave this at \"None\"\n",
    "#\n",
    "# When using augmented inference, if you leave this at \"None\", run_inference_with_yolov5_val.py\n",
    "# will use its default size, which is 1280 * 1.3, which is almost always what you want.\n",
    "image_size = None\n",
    "\n",
    "# Should we include image size, timestamp, and/or EXIF data in MD output?\n",
    "include_image_size = False\n",
    "include_image_timestamp = False\n",
    "include_exif_data = False\n",
    "\n",
    "# String to pass as the \"detector_options\" parameter to run_detector_batch (or None)\n",
    "# detector_options = 'compatibility_mode=classic'\n",
    "# detector_options = 'compatibility_mode=modern'\n",
    "detector_options = None\n",
    "\n",
    "# Only relevant when running on CPU\n",
    "ncores = 1\n",
    "\n",
    "# If False, we'll load chunk files with file lists if they exist\n",
    "force_enumeration = False\n",
    "\n",
    "# Prefer threads on Windows, processes on Linux\n",
    "parallelization_defaults_to_threads = False\n",
    "\n",
    "# This is for things like image rendering, not for MegaDetector\n",
    "default_workers_for_parallel_tasks = 30\n",
    "\n",
    "overwrite_handling = 'skip' # 'skip', 'error', or 'overwrite'\n",
    "\n",
    "# The function used to get camera names from image paths, used only for repeat\n",
    "# detection elimination.  This defaults to a standard function (image_file_to_camera_folder)\n",
    "# that replaces typical strings like \"BTCF\", \"RECNYX001\", or \"DCIM\".  There's an example near\n",
    "# the end of this notebook of using a custom function instead.\n",
    "relative_path_to_location = image_file_to_camera_folder\n",
    "\n",
    "# OS-specific script line continuation character (modified later if we're running on Windows)\n",
    "slcc = '\\\\'\n",
    "\n",
    "# OS-specific script comment character (modified later if we're running on Windows)\n",
    "scc = '#'\n",
    "\n",
    "# OS-specific script extension (modified later if we're running on Windows)\n",
    "script_extension = '.sh'\n",
    "\n",
    "# Stuff we stick into scripts to ensure early termination if there's an error\n",
    "script_header = '#!/bin/bash\\n\\nset -e\\n'\n",
    "\n",
    "# Include this after each command in a .sh/.bat file\n",
    "command_suffix = ''\n",
    "\n",
    "if os.name == 'nt':\n",
    "\n",
    "    script_header = ''\n",
    "    slcc = '^'\n",
    "    scc = 'REM'\n",
    "    script_extension = '.bat'\n",
    "\n",
    "    command_suffix = 'if %errorlevel% neq 0 exit /b %errorlevel%\\n'\n",
    "\n",
    "    # My experience has been that Python multiprocessing is flaky on Windows, so\n",
    "    # default to threads on Windows\n",
    "    parallelization_defaults_to_threads = True\n",
    "    default_workers_for_parallel_tasks = 10\n",
    "\n",
    "\n",
    "## Constants related to using YOLOv5's val.py\n",
    "\n",
    "# Should we use YOLOv5's val.py instead of run_detector_batch.py?\n",
    "use_yolo_inference_scripts = False\n",
    "\n",
    "# Directory in which to run val.py (relevant for YOLOv5, not for YOLOv8)\n",
    "yolo_working_dir = os.path.expanduser('~/git/yolov5')\n",
    "\n",
    "# Only used for loading the mapping from class indices to names\n",
    "yolo_dataset_file = None\n",
    "\n",
    "# 'yolov5' or 'yolov8'; assumes YOLOv5 if this is None\n",
    "yolo_model_type = None\n",
    "\n",
    "# Inference batch size\n",
    "yolo_batch_size = 1\n",
    "\n",
    "# Should we remove intermediate files used for running YOLOv5's val.py?\n",
    "#\n",
    "# Only relevant if use_yolo_inference_scripts is True.\n",
    "remove_yolo_intermediate_results = True\n",
    "remove_yolo_symlink_folder = True\n",
    "use_symlinks_for_yolo_inference = True\n",
    "write_yolo_debug_output = False\n",
    "\n",
    "# Should we apply YOLOv5's test-time augmentation?\n",
    "augment = False\n",
    "\n",
    "\n",
    "## Constants related to tiled inference\n",
    "\n",
    "use_tiled_inference = False\n",
    "\n",
    "# Should we delete tiles after each job?  Only set this to False for debugging;\n",
    "# large jobs will take up a lot of space if you keep tiles around after each task.\n",
    "remove_tiles = True\n",
    "tile_size = (1280,1280)\n",
    "tile_overlap = 0.2\n",
    "\n",
    "\n",
    "## Constants related to preview generation\n",
    "\n",
    "# Optionally omit non-animal images from the output, useful when animals are rare and\n",
    "# we want to dial up the total number of images used in the preview\n",
    "render_animals_only = False\n",
    "\n",
    "preview_options_base = PostProcessingOptions()\n",
    "preview_options_base.image_base_dir = None\n",
    "preview_options_base.include_almost_detections = True\n",
    "preview_options_base.num_images_to_sample = 7500\n",
    "preview_options_base.confidence_threshold = 0.2\n",
    "preview_options_base.almost_detection_confidence_threshold = \\\n",
    "    preview_options_base.confidence_threshold - 0.05\n",
    "preview_options_base.ground_truth_json_file = None\n",
    "preview_options_base.separate_detections_by_category = True\n",
    "preview_options_base.sample_seed = 0\n",
    "preview_options_base.max_figures_per_html_file = 2500\n",
    "preview_options_base.sort_classification_results_by_count = True\n",
    "preview_options_base.parallelize_rendering = True\n",
    "preview_options_base.parallelize_rendering_n_cores = default_workers_for_parallel_tasks\n",
    "preview_options_base.parallelize_rendering_with_threads = parallelization_defaults_to_threads\n",
    "preview_options_base.additional_image_fields_to_display = \\\n",
    "    {'pre_smoothing_description':'pre-smoothing labels',\n",
    "     'pre_filtering_description':'pre-filtering labels',\n",
    "     'top_classification_common_name':'top class'}\n",
    "\n",
    "if render_animals_only:\n",
    "    preview_options_base.rendering_bypass_sets = ['detections_person','detections_vehicle',\n",
    "                                     'detections_person_vehicle','non_detections']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628affab",
   "metadata": {},
   "source": [
    "## Variables I set for each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca1e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/drive/organization'\n",
    "organization_name_short = 'organization'\n",
    "job_date = None # '2025-01-01'\n",
    "model_file = 'MDV5A' # 'MDV5A', 'MDV5B', 'MDV4'\n",
    "\n",
    "# Number of jobs to split data into, typically equal to the number of available GPUs, though\n",
    "# when using an image loading queue, I typically use ~100 jobs per GPU;  those serve as de\n",
    "# facto checkpoints.\n",
    "n_jobs = 100\n",
    "n_gpus = 2\n",
    "\n",
    "# Set to \"None\" when using an image loading queue, which doesn't currently support\n",
    "# checkpointing.  Don't worry, this will be assert()'d in the next cell.\n",
    "checkpoint_frequency = None\n",
    "\n",
    "# Local root folder where we do all our MegaDetector work; results and\n",
    "# temporary files will be stored in a subfolder for this job\n",
    "postprocessing_base = os.path.expanduser('~/postprocessing')\n",
    "\n",
    "# Optional job descriptor (separated by \"-\", so you don't have to include the delimiter here)\n",
    "job_tag = None\n",
    "\n",
    "# SpeciesNet-related variables\n",
    "\n",
    "speciesnet_model_file = os.path.expanduser('~/models/speciesnet/crop')\n",
    "\n",
    "country_code = None\n",
    "state_code = None\n",
    "\n",
    "speciesnet_folder = os.path.expanduser('~/git/cameratrapai')\n",
    "speciesnet_detector_environment_name = 'speciesnet' #'speciesnet-package-pytorch'\n",
    "speciesnet_classifier_environment_name = 'speciesnet' # 'speciesnet-package-tf'\n",
    "\n",
    "# Can be None to run the classifier in a single chunk\n",
    "max_images_per_chunk = None\n",
    "classifier_batch_size = 128\n",
    "\n",
    "# Text file containing binomial names and common names of allowed taxa\n",
    "custom_taxa_list = None\n",
    "\n",
    "# If custom_taxa_list is not None, when should we apply the custom taxonomy?  Can be\n",
    "# 'before_smoothing' or 'after_smoothing'.\n",
    "custom_taxa_stage = 'before_smoothing'\n",
    "\n",
    "custom_taxa_allow_walk_down = False\n",
    "\n",
    "# Only necessary when using a custom taxonomy list\n",
    "taxonomy_file = path_join(speciesnet_model_file,'taxonomy_release.txt')\n",
    "\n",
    "# Setting this to True says that if I have two predicted species in the same family\n",
    "# in a sequence, I will force them all to be the more common species.  Don't set this\n",
    "# if you have images where multiple species from the same family can occur in the same\n",
    "# sequence.\n",
    "allow_same_family_smoothing = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e66283",
   "metadata": {},
   "source": [
    "## Derived variables, constant validation, path setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6072184",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = input_path.replace('\\\\','/')\n",
    "\n",
    "assert not (input_path.endswith('/') or input_path.endswith('\\\\'))\n",
    "assert os.path.isdir(input_path), 'Could not find input folder {}'.format(input_path)\n",
    "assert job_date is not None and organization_name_short != 'organization'\n",
    "\n",
    "if job_tag is None:\n",
    "    job_description_string = ''\n",
    "else:\n",
    "    job_description_string = '-' + job_tag\n",
    "\n",
    "# Estimate inference speed for the current GPU\n",
    "approx_images_per_second = estimate_md_images_per_second(model_file)\n",
    "\n",
    "# Rough estimate for the inference time cost of augmentation\n",
    "if augment and (approx_images_per_second is not None):\n",
    "    approx_images_per_second = approx_images_per_second * 0.7\n",
    "\n",
    "base_task_name = organization_name_short + '-' + job_date + job_description_string + '-' + \\\n",
    "    get_detector_version_from_model_file(model_file)\n",
    "base_output_folder_name = \\\n",
    "    path_join(postprocessing_base,organization_name_short)\n",
    "os.makedirs(base_output_folder_name,exist_ok=True)\n",
    "\n",
    "if use_image_queue:\n",
    "    assert checkpoint_frequency is None,\\\n",
    "        'Checkpointing is not supported when using an image queue'\n",
    "\n",
    "if augment:\n",
    "    assert checkpoint_frequency is None,\\\n",
    "        'Checkpointing is not supported when using augmentation'\n",
    "\n",
    "    assert use_yolo_inference_scripts,\\\n",
    "        'Augmentation is only supported when running with the YOLO inference scripts'\n",
    "\n",
    "if use_tiled_inference:\n",
    "    assert not augment, \\\n",
    "        'Augmentation is not supported when using tiled inference'\n",
    "    assert not use_yolo_inference_scripts, \\\n",
    "        'Using the YOLO inference script is not supported when using tiled inference'\n",
    "    assert checkpoint_frequency is None, \\\n",
    "        'Checkpointing is not supported when using tiled inference'\n",
    "\n",
    "filename_base = path_join(base_output_folder_name, base_task_name)\n",
    "combined_api_output_folder = path_join(filename_base, 'combined_api_outputs')\n",
    "postprocessing_output_folder = path_join(filename_base, 'preview')\n",
    "\n",
    "combined_api_output_file = path_join(\n",
    "    combined_api_output_folder,\n",
    "    '{}_detections.json'.format(base_task_name))\n",
    "\n",
    "# This will be the .json results file after RDE; if this doesn't exist when\n",
    "# we get to classification stuff, that will indicate that we didn't do RDE.\n",
    "filtered_output_filename = insert_before_extension(combined_api_output_file,'filtered')\n",
    "\n",
    "# If we do sequence-level smoothing, we'll read EXIF data and put it here\n",
    "exif_results_file = path_join(filename_base,'exif_data.json')\n",
    "\n",
    "os.makedirs(filename_base, exist_ok=True)\n",
    "os.makedirs(combined_api_output_folder, exist_ok=True)\n",
    "os.makedirs(postprocessing_output_folder, exist_ok=True)\n",
    "\n",
    "if input_path.endswith('/'):\n",
    "    input_path = input_path[0:-1]\n",
    "\n",
    "print('Output folder:\\n{}'.format(filename_base))\n",
    "\n",
    "if custom_taxa_list is not None:\n",
    "\n",
    "    assert os.path.isfile(custom_taxa_list), \\\n",
    "        'Could not find custom taxa file {}'.format(custom_taxa_list)\n",
    "    assert os.path.isfile(taxonomy_file), \\\n",
    "        'Could not find taxonomy file {}'.format(taxonomy_file)\n",
    "    assert custom_taxa_stage in ('before_smoothing','after_smoothing')\n",
    "\n",
    "    # Validate the species list\n",
    "    from megadetector.utils.wi_utils import restrict_to_taxa_list\n",
    "    restrict_to_taxa_list(custom_taxa_list,taxonomy_file,None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c218de",
   "metadata": {},
   "source": [
    "## Enumerate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21870ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have we already listed files for this job?\n",
    "chunk_file_base = path_join(filename_base,'file_chunks')\n",
    "os.makedirs(chunk_file_base,exist_ok=True)\n",
    "\n",
    "chunk_files = os.listdir(chunk_file_base)\n",
    "pattern = re.compile('chunk\\d+.json')\n",
    "chunk_files = [fn for fn in chunk_files if pattern.match(fn)]\n",
    "\n",
    "if (not force_enumeration) and (len(chunk_files) > 0):\n",
    "\n",
    "    print('Found {} chunk files in folder {}, bypassing enumeration'.format(\n",
    "        len(chunk_files),\n",
    "        filename_base))\n",
    "\n",
    "    all_images = []\n",
    "    for fn in chunk_files:\n",
    "        with open(path_join(chunk_file_base,fn),'r') as f:\n",
    "            chunk = json.load(f)\n",
    "            assert isinstance(chunk,list)\n",
    "            all_images.extend(chunk)\n",
    "    all_images = sorted(all_images)\n",
    "\n",
    "    print('Loaded {} image files from {} chunks in {}'.format(\n",
    "        len(all_images),len(chunk_files),chunk_file_base))\n",
    "\n",
    "else:\n",
    "\n",
    "    print('Enumerating image files in {}'.format(input_path))\n",
    "\n",
    "    all_images = sorted(find_images(input_path,recursive=True,convert_slashes=True))\n",
    "\n",
    "    # It's common to run this notebook on an external drive with the main folders in the drive root\n",
    "    all_images = [fn for fn in all_images if not \\\n",
    "                  (fn.startswith('$RECYCLE') or fn.startswith('System Volume Information'))]\n",
    "\n",
    "    print('')\n",
    "\n",
    "    print('Enumerated {} image files in {}'.format(len(all_images),input_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91758d",
   "metadata": {},
   "source": [
    "## Divide images into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ce7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_chunks = split_list_into_n_chunks(all_images,n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f584a",
   "metadata": {},
   "source": [
    "## Estimate total time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9480df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if approx_images_per_second is None:\n",
    "\n",
    "    print(\"Can't estimate inference time for the current environment\")\n",
    "\n",
    "else:\n",
    "\n",
    "    n_images = len(all_images)\n",
    "    execution_seconds = n_images / approx_images_per_second\n",
    "    wallclock_seconds = execution_seconds / n_gpus\n",
    "    print('Expected time: {}'.format(humanfriendly.format_timespan(wallclock_seconds)))\n",
    "\n",
    "    seconds_per_chunk = len(folder_chunks[0]) / approx_images_per_second\n",
    "    print('Expected time per chunk: {}'.format(humanfriendly.format_timespan(seconds_per_chunk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f034b6a",
   "metadata": {},
   "source": [
    "## Write file lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_info = []\n",
    "\n",
    "for i_chunk,chunk_list in enumerate(folder_chunks):\n",
    "\n",
    "    chunk_fn = path_join(chunk_file_base,'chunk{}.json'.format(str(i_chunk).zfill(3)))\n",
    "    task_info.append({'id':i_chunk,'input_file':chunk_fn})\n",
    "    write_list_to_file(chunk_fn, chunk_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7245ddf",
   "metadata": {},
   "source": [
    "## Generate commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of the scripts tied to each GPU, as absolute paths.  We'll write this out at\n",
    "# the end so each GPU's list of commands can be run at once\n",
    "gpu_to_scripts = defaultdict(list)\n",
    "\n",
    "detector_chunk_base = path_join(filename_base,'detector_commands')\n",
    "os.makedirs(detector_chunk_base,exist_ok=True)\n",
    "\n",
    "# i_task = 0; task = task_info[i_task]\n",
    "for i_task,task in enumerate(task_info):\n",
    "\n",
    "    chunk_file = task['input_file']\n",
    "    checkpoint_filename = chunk_file.replace('.json','_checkpoint.json')\n",
    "\n",
    "    output_fn = chunk_file.replace('.json','_results.json')\n",
    "\n",
    "    task['output_file'] = output_fn\n",
    "\n",
    "    if n_gpus > 1:\n",
    "        gpu_number = i_task % n_gpus\n",
    "    else:\n",
    "        gpu_number = default_gpu_number\n",
    "\n",
    "    image_size_string = ''\n",
    "    if image_size is not None:\n",
    "        image_size_string = '--image_size {}'.format(image_size)\n",
    "\n",
    "    # Generate the script to run MD\n",
    "\n",
    "    if use_yolo_inference_scripts:\n",
    "\n",
    "        augment_string = ''\n",
    "        if augment:\n",
    "            augment_string = '--augment_enabled 1'\n",
    "        else:\n",
    "            augment_string = '--augment_enabled 0'\n",
    "\n",
    "        batch_string = '--batch_size {}'.format(yolo_batch_size)\n",
    "\n",
    "        symlink_folder = path_join(filename_base,'symlinks','symlinks_{}'.format(\n",
    "            str(i_task).zfill(3)))\n",
    "        yolo_results_folder = path_join(filename_base,'yolo_results','yolo_results_{}'.format(\n",
    "            str(i_task).zfill(3)))\n",
    "\n",
    "        symlink_folder_string = '--symlink_folder \"{}\"'.format(symlink_folder)\n",
    "        yolo_results_folder_string = '--yolo_results_folder \"{}\"'.format(yolo_results_folder)\n",
    "\n",
    "        remove_symlink_folder_string = ''\n",
    "        if not remove_yolo_symlink_folder:\n",
    "            remove_symlink_folder_string = '--no_remove_symlink_folder'\n",
    "\n",
    "        write_yolo_debug_output_string = ''\n",
    "        if write_yolo_debug_output:\n",
    "            write_yolo_debug_output = '--write_yolo_debug_output'\n",
    "\n",
    "        remove_yolo_results_string = ''\n",
    "        if not remove_yolo_intermediate_results:\n",
    "            remove_yolo_results_string = '--no_remove_yolo_results_folder'\n",
    "\n",
    "        confidence_threshold_string = ''\n",
    "        if json_threshold is not None:\n",
    "            confidence_threshold_string = '--conf_thres {}'.format(json_threshold)\n",
    "        else:\n",
    "            confidence_threshold_string = '--conf_thres {}'.format(DEFAULT_OUTPUT_CONFIDENCE_THRESHOLD)\n",
    "\n",
    "        cmd = ''\n",
    "\n",
    "        device_string = '--device {}'.format(gpu_number)\n",
    "\n",
    "        overwrite_handling_string = '--overwrite_handling {}'.format(overwrite_handling)\n",
    "\n",
    "        cmd += f'python run_inference_with_yolov5_val.py \"{model_file}\" \"{chunk_file}\" \"{output_fn}\" '\n",
    "        cmd += f'{image_size_string} {augment_string} '\n",
    "        cmd += f'{symlink_folder_string} {yolo_results_folder_string} {remove_yolo_results_string} '\n",
    "        cmd += f'{remove_symlink_folder_string} {confidence_threshold_string} {device_string} '\n",
    "        cmd += f'{overwrite_handling_string} {batch_string} {write_yolo_debug_output_string}'\n",
    "\n",
    "        if yolo_working_dir is not None:\n",
    "            cmd += f' --yolo_working_folder \"{yolo_working_dir}\"'\n",
    "        if yolo_dataset_file is not None:\n",
    "            cmd += ' --yolo_dataset_file \"{}\"'.format(yolo_dataset_file)\n",
    "        if yolo_model_type is not None:\n",
    "            cmd += ' --model_type {}'.format(yolo_model_type)\n",
    "\n",
    "        if not use_symlinks_for_yolo_inference:\n",
    "            cmd += ' --no_use_symlinks'\n",
    "\n",
    "        cmd += '\\n'\n",
    "\n",
    "    elif use_tiled_inference:\n",
    "\n",
    "        tiling_folder = path_join(filename_base,'tile_cache','tile_cache_{}'.format(\n",
    "            str(i_task).zfill(3)))\n",
    "\n",
    "        if os.name == 'nt':\n",
    "            cuda_string = f'set CUDA_VISIBLE_DEVICES={gpu_number} & '\n",
    "        else:\n",
    "            cuda_string = f'CUDA_VISIBLE_DEVICES={gpu_number} '\n",
    "\n",
    "        cmd = f'{cuda_string} python run_tiled_inference.py \"{model_file}\" \"{input_path}\" \"{tiling_folder}\" \"{output_fn}\"'\n",
    "\n",
    "        cmd += f' --image_list \"{chunk_file}\"'\n",
    "        cmd += f' --overwrite_handling {overwrite_handling}'\n",
    "\n",
    "        if not remove_tiles:\n",
    "            cmd += ' --no_remove_tiles'\n",
    "\n",
    "        # If we're using non-default tile sizes\n",
    "        if tile_size is not None and (tile_size[0] > 0 or tile_size[1] > 0):\n",
    "            cmd += ' --tile_size_x {} --tile_size_y {}'.format(tile_size[0],tile_size[1])\n",
    "\n",
    "        if tile_overlap is not None:\n",
    "            cmd += f' --tile_overlap {tile_overlap}'\n",
    "\n",
    "    else:\n",
    "\n",
    "        if os.name == 'nt':\n",
    "            cuda_string = f'set CUDA_VISIBLE_DEVICES={gpu_number} & '\n",
    "        else:\n",
    "            cuda_string = f'CUDA_VISIBLE_DEVICES={gpu_number} '\n",
    "\n",
    "        checkpoint_frequency_string = ''\n",
    "        checkpoint_path_string = ''\n",
    "\n",
    "        if checkpoint_frequency is not None and checkpoint_frequency > 0:\n",
    "            checkpoint_frequency_string = f'--checkpoint_frequency {checkpoint_frequency}'\n",
    "            checkpoint_path_string = '--checkpoint_path \"{}\"'.format(checkpoint_filename)\n",
    "\n",
    "        use_image_queue_string = ''\n",
    "        if (use_image_queue):\n",
    "            use_image_queue_string = '--use_image_queue'\n",
    "            if preprocess_on_image_queue:\n",
    "                use_image_queue_string += ' --preprocess_on_image_queue'\n",
    "            if image_queue_loader_workers is not None:\n",
    "                use_image_queue_string += ' --loader_workers {}'.format(image_queue_loader_workers)\n",
    "\n",
    "        ncores_string = ''\n",
    "        if (ncores > 1):\n",
    "            ncores_string = '--ncores {}'.format(ncores)\n",
    "\n",
    "        quiet_string = ''\n",
    "        if quiet_mode:\n",
    "            quiet_string = '--quiet'\n",
    "\n",
    "        confidence_threshold_string = ''\n",
    "        if json_threshold is not None:\n",
    "            confidence_threshold_string = '--threshold {}'.format(json_threshold)\n",
    "\n",
    "        overwrite_handling_string = '--overwrite_handling {}'.format(overwrite_handling)\n",
    "        cmd = f'{cuda_string} python run_detector_batch.py \"{model_file}\" \"{chunk_file}\" \"{output_fn}\" {checkpoint_frequency_string} {checkpoint_path_string} {use_image_queue_string} {ncores_string} {quiet_string} {image_size_string} {confidence_threshold_string} {overwrite_handling_string}'\n",
    "\n",
    "        if include_image_size:\n",
    "            cmd += ' --include_image_size'\n",
    "        if include_image_timestamp:\n",
    "            cmd += ' --include_image_timestamp'\n",
    "        if include_exif_data:\n",
    "            cmd += ' --include_exif_data'\n",
    "\n",
    "        if detector_options is not None:\n",
    "            cmd += ' --detector_options \"{}\"'.format(detector_options)\n",
    "\n",
    "    cmd_file = path_join(filename_base,'detector_commands',\n",
    "                            'run_chunk_{}_gpu_{}{}'.format(str(i_task).zfill(3),\n",
    "                            str(gpu_number).zfill(2),script_extension))\n",
    "\n",
    "    with open(cmd_file,'w') as f:\n",
    "\n",
    "        # This writes, e.g. \"set -e\"\n",
    "        if script_header is not None and len(script_header) > 0:\n",
    "            f.write(script_header + '\\n')\n",
    "\n",
    "        f.write(cmd + '\\n')\n",
    "\n",
    "    st = os.stat(cmd_file)\n",
    "    os.chmod(cmd_file, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "    task['command'] = cmd\n",
    "    task['command_file'] = cmd_file\n",
    "\n",
    "    # Generate the script to resume from the checkpoint (only supported with MD inference code)\n",
    "\n",
    "    gpu_to_scripts[gpu_number].append(cmd_file)\n",
    "\n",
    "    if checkpoint_frequency is not None:\n",
    "\n",
    "        resume_string = ' --resume_from_checkpoint \"{}\"'.format(checkpoint_filename)\n",
    "        resume_cmd = cmd + resume_string\n",
    "\n",
    "        resume_cmd_file = path_join(filename_base,'detector_commands',\n",
    "                                       'resume_chunk_{}_gpu_{}{}'.format(str(i_task).zfill(3),\n",
    "                                       str(gpu_number).zfill(2),script_extension))\n",
    "\n",
    "        with open(resume_cmd_file,'w') as f:\n",
    "\n",
    "            # This writes, e.g. \"set -e\"\n",
    "            if script_header is not None and len(script_header) > 0:\n",
    "                f.write(script_header + '\\n')\n",
    "\n",
    "            f.write(resume_cmd + '\\n')\n",
    "\n",
    "        st = os.stat(resume_cmd_file)\n",
    "        os.chmod(resume_cmd_file, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "        task['resume_command'] = resume_cmd\n",
    "        task['resume_command_file'] = resume_cmd_file\n",
    "\n",
    "# ...for each task\n",
    "\n",
    "# Write out a script for each GPU that runs all of the commands associated with\n",
    "# that GPU.\n",
    "for gpu_number in gpu_to_scripts:\n",
    "\n",
    "    gpu_script_file = path_join(filename_base,'run_all_for_gpu_{}{}'.format(\n",
    "        str(gpu_number).zfill(2),script_extension))\n",
    "\n",
    "    with open(gpu_script_file,'w') as f:\n",
    "\n",
    "        # This writes, e.g. \"set -e\"\n",
    "        if script_header is not None and len(script_header) > 0:\n",
    "            f.write(script_header + '\\n')\n",
    "\n",
    "        for script_name in gpu_to_scripts[gpu_number]:\n",
    "            s = script_name\n",
    "            # When calling a series of batch files on Windows from within a batch file, you need to\n",
    "            # use \"call\", or only the first will be executed.  No, it doesn't make sense.\n",
    "            if os.name == 'nt':\n",
    "                s = 'call ' + s\n",
    "            f.write(s + '\\n')\n",
    "\n",
    "        f.write('echo \"Finished all commands for GPU {}\"'.format(gpu_number))\n",
    "\n",
    "    st = os.stat(gpu_script_file)\n",
    "    os.chmod(gpu_script_file, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "# ...for each GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78478661",
   "metadata": {},
   "source": [
    "## Run the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36cc234",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "tl;dr: I almost never run this cell.\n",
    "\n",
    "Long version...\n",
    "\n",
    "The cells we've run so far wrote out some shell scripts (.bat files on Windows,\n",
    ".sh files on Linx/Mac) that will run MegaDetector.  I like to leave the interactive\n",
    "environment at this point and run those scripts at the command line.  So, for example,\n",
    "if you're on Windows, and you've basically used the default values above, there will be\n",
    "batch files called, e.g.:\n",
    "\n",
    "c:\\users\\[username]\\postprocessing\\[organization]\\[job_name]\\run_chunk_000_gpu_00.bat\n",
    "c:\\users\\[username]\\postprocessing\\[organization]\\[job_name]\\run_chunk_001_gpu_01.bat\n",
    "\n",
    "Those batch files expect to be run from the \"detection\" folder of the MegaDetector repo,\n",
    "typically:\n",
    "\n",
    "c:\\git\\MegaDetector\\megadetector\\detection\n",
    "\n",
    "All of that said, you don't *have* to do this at the command line.  The following cell\n",
    "runs these scripts programmatically, so if you set \"run_tasks_in_notebook\" to \"True\"\n",
    "and run this cell, you can run MegaDetector without leaving this notebook.\n",
    "\n",
    "One downside of the programmatic approach is that this cell doesn't yet parallelize over\n",
    "multiple processes, so the tasks will run serially.  This only matters if you have\n",
    "multiple GPUs.\n",
    "\"\"\"\n",
    "\n",
    "run_tasks_in_notebook = False\n",
    "\n",
    "if run_tasks_in_notebook:\n",
    "\n",
    "    assert not use_yolo_inference_scripts, \\\n",
    "        'If you want to use the YOLOv5 inference scripts, you can\\'t run the model interactively (yet)'\n",
    "\n",
    "    # i_task = 0; task = task_info[i_task]\n",
    "    for i_task,task in enumerate(task_info):\n",
    "\n",
    "        chunk_file = task['input_file']\n",
    "        output_fn = task['output_file']\n",
    "\n",
    "        checkpoint_filename = chunk_file.replace('.json','_checkpoint.json')\n",
    "\n",
    "        if json_threshold is not None:\n",
    "            confidence_threshold = json_threshold\n",
    "        else:\n",
    "            confidence_threshold = DEFAULT_OUTPUT_CONFIDENCE_THRESHOLD\n",
    "\n",
    "        if checkpoint_frequency is not None and checkpoint_frequency > 0:\n",
    "            cp_freq_arg = checkpoint_frequency\n",
    "        else:\n",
    "            cp_freq_arg = -1\n",
    "\n",
    "        start_time = time.time()\n",
    "        results = load_and_run_detector_batch(model_file=model_file,\n",
    "                                              image_file_names=chunk_file,\n",
    "                                              checkpoint_path=checkpoint_filename,\n",
    "                                              confidence_threshold=confidence_threshold,\n",
    "                                              checkpoint_frequency=cp_freq_arg,\n",
    "                                              results=None,\n",
    "                                              n_cores=ncores,\n",
    "                                              use_image_queue=use_image_queue,\n",
    "                                              quiet=quiet_mode,\n",
    "                                              image_size=image_size)\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print('Task {}: finished inference for {} images in {}'.format(\n",
    "            i_task, len(results),humanfriendly.format_timespan(elapsed)))\n",
    "\n",
    "        # This will write absolute paths to the file, we'll fix this later\n",
    "        write_results_to_file(results, output_fn, detector_file=model_file)\n",
    "\n",
    "        if checkpoint_frequency is not None and checkpoint_frequency > 0:\n",
    "            if os.path.isfile(checkpoint_filename):\n",
    "                os.remove(checkpoint_filename)\n",
    "                print('Deleted checkpoint file {}'.format(checkpoint_filename))\n",
    "\n",
    "    # ...for each chunk\n",
    "\n",
    "# ...if we're running tasks in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c256c2",
   "metadata": {},
   "source": [
    "## Load results, look for failed or missing images in each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all task output files exist\n",
    "\n",
    "missing_output_files = []\n",
    "\n",
    "# i_task = 0; task = task_info[i_task]\n",
    "for i_task,task in tqdm(enumerate(task_info),total=len(task_info)):\n",
    "    output_file = task['output_file']\n",
    "    if not os.path.isfile(output_file):\n",
    "        missing_output_files.append(output_file)\n",
    "\n",
    "if len(missing_output_files) > 0:\n",
    "    print('Missing {} output files:'.format(len(missing_output_files)))\n",
    "    for s in missing_output_files:\n",
    "        print(s)\n",
    "    raise Exception('Missing output files')\n",
    "\n",
    "n_total_failures = 0\n",
    "\n",
    "# i_task = 0; task = task_info[i_task]\n",
    "for i_task,task in tqdm(enumerate(task_info),total=len(task_info)):\n",
    "\n",
    "    chunk_file = task['input_file']\n",
    "    output_file = task['output_file']\n",
    "\n",
    "    with open(chunk_file,'r') as f:\n",
    "        task_images = json.load(f)\n",
    "    with open(output_file,'r') as f:\n",
    "        task_results = json.load(f)\n",
    "\n",
    "    task_images_set = set(task_images)\n",
    "    filename_to_results = {}\n",
    "\n",
    "    n_task_failures = 0\n",
    "\n",
    "    # im = task_results['images'][0]\n",
    "    for im in task_results['images']:\n",
    "\n",
    "        # Most of the time, inference result files use absolute paths, but it's\n",
    "        # getting annoying to make sure that's *always* true, so handle both here.\n",
    "        # E.g., when using tiled inference, paths will be relative.\n",
    "        if not os.path.isabs(im['file']):\n",
    "            fn = path_join(input_path,im['file'])\n",
    "            im['file'] = fn\n",
    "        assert im['file'].startswith(input_path)\n",
    "        assert im['file'] in task_images_set\n",
    "        filename_to_results[im['file']] = im\n",
    "        if 'failure' in im:\n",
    "            assert im['failure'] is not None\n",
    "            n_task_failures += 1\n",
    "\n",
    "    task['n_failures'] = n_task_failures\n",
    "    task['results'] = task_results\n",
    "\n",
    "    for fn in task_images:\n",
    "        assert fn in filename_to_results, \\\n",
    "            'File {} not found in results for task {}'.format(fn,i_task)\n",
    "\n",
    "    n_total_failures += n_task_failures\n",
    "\n",
    "# ...for each task\n",
    "\n",
    "assert n_total_failures < max_tolerable_failed_images,\\\n",
    "    '{} failures (max tolerable set to {})'.format(n_total_failures,\n",
    "                                                   max_tolerable_failed_images)\n",
    "\n",
    "print('Processed all {} images with {} failures'.format(\n",
    "    len(all_images),n_total_failures))\n",
    "\n",
    "\n",
    "##%% Merge results files and make filenames relative\n",
    "\n",
    "combined_results = {}\n",
    "combined_results['images'] = []\n",
    "images_processed = set()\n",
    "\n",
    "for i_task,task in tqdm(enumerate(task_info),total=len(task_info)):\n",
    "\n",
    "    task_results = task['results']\n",
    "\n",
    "    if i_task == 0:\n",
    "        combined_results['info'] = task_results['info']\n",
    "        combined_results['detection_categories'] = task_results['detection_categories']\n",
    "    else:\n",
    "        assert task_results['info']['format_version'] == combined_results['info']['format_version']\n",
    "        assert task_results['detection_categories'] == combined_results['detection_categories']\n",
    "\n",
    "    # Make sure we didn't see this image in another chunk\n",
    "    for im in task_results['images']:\n",
    "        assert im['file'] not in images_processed\n",
    "        images_processed.add(im['file'])\n",
    "\n",
    "    combined_results['images'].extend(task_results['images'])\n",
    "\n",
    "# Check that we ended up with the right number of images\n",
    "assert len(combined_results['images']) == len(all_images), \\\n",
    "    'Expected {} images in combined results, found {}'.format(\n",
    "        len(all_images),len(combined_results['images']))\n",
    "\n",
    "# Check uniqueness\n",
    "result_filenames = [im['file'] for im in combined_results['images']]\n",
    "assert len(combined_results['images']) == len(set(result_filenames))\n",
    "\n",
    "# Convert to relative paths, preserving '/' as the path separator, regardless of OS\n",
    "for im in combined_results['images']:\n",
    "    assert '\\\\' not in im['file']\n",
    "    assert im['file'].startswith(input_path)\n",
    "    if input_path.endswith(':'):\n",
    "        im['file'] = im['file'].replace(input_path,'',1)\n",
    "    else:\n",
    "        im['file'] = im['file'].replace(input_path + '/','',1)\n",
    "\n",
    "with open(combined_api_output_file,'w') as f:\n",
    "    json.dump(combined_results,f,indent=1)\n",
    "\n",
    "print('\\nWrote results to {}'.format(combined_api_output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c2d46",
   "metadata": {},
   "source": [
    "## Post-processing (pre-RDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NB: I almost never run this cell.  This preview the results *before* repeat detection\n",
    "elimination (RDE), but since I'm essentially always doing RDE, I'm basically never\n",
    "interested in this preview.  There is a similar cell below for previewing results\n",
    "*after* RDE, which I almost always run.\n",
    "\"\"\"\n",
    "\n",
    "preview_options = deepcopy(preview_options_base)\n",
    "preview_options.image_base_dir = input_path\n",
    "\n",
    "preview_folder = path_join(postprocessing_output_folder,\n",
    "    base_task_name + '_{:.3f}'.format(preview_options.confidence_threshold))\n",
    "\n",
    "os.makedirs(preview_folder, exist_ok=True)\n",
    "\n",
    "preview_options.md_results_file = combined_api_output_file\n",
    "preview_options.output_dir = preview_folder\n",
    "\n",
    "print('Generating pre-RDE preview in {}'.format(preview_folder))\n",
    "ppresults = process_batch_results(preview_options)\n",
    "open_file(ppresults.output_html_file,attempt_to_open_in_wsl_host=True,browser_name='chrome')\n",
    "# import clipboard; clipboard.copy(ppresults.output_html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad413370",
   "metadata": {},
   "source": [
    "## Repeat detection elimination, phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.postprocessing.repeat_detection_elimination import repeat_detections_core\n",
    "\n",
    "task_index = 0\n",
    "\n",
    "options = repeat_detections_core.RepeatDetectionOptions()\n",
    "\n",
    "options.confidenceMin = 0.1\n",
    "options.confidenceMax = 1.01\n",
    "options.iouThreshold = 0.85\n",
    "options.occurrenceThreshold = 15\n",
    "options.maxSuspiciousDetectionSize = 0.2\n",
    "# options.minSuspiciousDetectionSize = 0.05\n",
    "\n",
    "options.parallelizationUsesThreads = parallelization_defaults_to_threads\n",
    "options.nWorkers = default_workers_for_parallel_tasks\n",
    "\n",
    "# This will cause a very light gray box to get drawn around all the detections\n",
    "# we're *not* considering as suspicious.\n",
    "options.bRenderOtherDetections = True\n",
    "options.otherDetectionsThreshold = options.confidenceMin\n",
    "\n",
    "options.bRenderDetectionTiles = True\n",
    "options.maxOutputImageWidth = 2000\n",
    "options.detectionTilesMaxCrops = 100\n",
    "\n",
    "# options.lineThickness = 5\n",
    "# options.boxExpansion = 8\n",
    "\n",
    "options.customDirNameFunction = relative_path_to_location\n",
    "\n",
    "# To invoke custom collapsing of folders for a particular naming scheme\n",
    "# options.customDirNameFunction = custom_relative_path_to_location\n",
    "\n",
    "# To treat a specific folder level as a camera, frequently used when the leaf\n",
    "# folders each contain frames extracted from a single video\n",
    "#\n",
    "# Setting this value to 0 is the same as treating each leaf folder as a camera.\n",
    "#\n",
    "# options.nDirLevelsFromLeaf = 1\n",
    "\n",
    "options.imageBase = input_path\n",
    "rde_string = 'rde_{:.3f}_{:.3f}_{}_{:.3f}'.format(\n",
    "    options.confidenceMin, options.iouThreshold,\n",
    "    options.occurrenceThreshold, options.maxSuspiciousDetectionSize)\n",
    "options.outputBase = path_join(filename_base, rde_string + '_task_{}'.format(task_index))\n",
    "options.filenameReplacements = None # {'':''}\n",
    "\n",
    "# Exclude people and vehicles from RDE\n",
    "# options.excludeClasses = [2,3]\n",
    "\n",
    "# options.maxImagesPerFolder = 50000\n",
    "# options.includeFolders = ['a/b/c','d/e/f']\n",
    "# options.excludeFolders = ['a/b/c','d/e/f']\n",
    "\n",
    "options.debugMaxDir = -1\n",
    "options.debugMaxRenderDir = -1\n",
    "options.debugMaxRenderDetection = -1\n",
    "options.debugMaxRenderInstance = -1\n",
    "\n",
    "# Can be None, 'xsort', or 'clustersort'\n",
    "options.smartSort = 'xsort'\n",
    "\n",
    "suspicious_detection_results = repeat_detections_core.find_repeat_detections(combined_api_output_file,\n",
    "                                                                             outputFilename=None,\n",
    "                                                                             options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc159ed4",
   "metadata": {},
   "source": [
    "## Manual RDE step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460add21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DELETE THE VALID DETECTIONS ##\n",
    "\n",
    "# If you run this line, it will open the folder up in your file browser\n",
    "open_file(os.path.dirname(suspicious_detection_results.filterFile),\n",
    "                     attempt_to_open_in_wsl_host=True)\n",
    "\n",
    "#\n",
    "# If you ran the previous cell, but then you change your mind and you don't want to do\n",
    "# the RDE step, that's fine, but don't just blast through this cell once you've run the\n",
    "# previous cell.  If you do that, you're implicitly telling the notebook that you looked\n",
    "# at everything in that folder, and confirmed there were no red boxes on animals.\n",
    "#\n",
    "# Instead, either change \"filtered_output_filename\" below to \"combined_api_output_file\",\n",
    "# or delete *all* the images in the filtering folder.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046faac",
   "metadata": {},
   "source": [
    "## Re-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb137368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.postprocessing.repeat_detection_elimination import remove_repeat_detections\n",
    "\n",
    "remove_repeat_detections.remove_repeat_detections(\n",
    "    inputFile=combined_api_output_file,\n",
    "    outputFile=filtered_output_filename,\n",
    "    filteringDir=os.path.dirname(suspicious_detection_results.filterFile)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2f527",
   "metadata": {},
   "source": [
    "## Post-processing (post-RDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb300015",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_options = deepcopy(preview_options_base)\n",
    "preview_options.image_base_dir = input_path\n",
    "\n",
    "preview_folder = path_join(postprocessing_output_folder,\n",
    "    base_task_name + '_{}_{:.3f}'.format(rde_string, preview_options.confidence_threshold))\n",
    "\n",
    "os.makedirs(preview_folder, exist_ok=True)\n",
    "\n",
    "preview_options.md_results_file = filtered_output_filename\n",
    "preview_options.output_dir = preview_folder\n",
    "\n",
    "print('Generating post-RDE preview in {}'.format(preview_folder))\n",
    "ppresults = process_batch_results(preview_options)\n",
    "open_file(ppresults.output_html_file,attempt_to_open_in_wsl_host=True,browser_name='chrome')\n",
    "# import clipboard; clipboard.copy(ppresults.output_html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d845e7c",
   "metadata": {},
   "source": [
    "## SpeciesNet derived constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detector/cropping constants\n",
    "\n",
    "# A results file in MD format, referring to the original images\n",
    "detection_results_file_with_crop_ids = path_join(combined_api_output_folder,\n",
    "                                                    base_task_name + '-detection_results_with_crop_ids.json')\n",
    "\n",
    "# A results file in MD format, referring to the crops, so every detection\n",
    "# has bbox [0,0,1,1]\n",
    "detection_results_file_for_crop_folder = insert_before_extension(\n",
    "        detection_results_file_with_crop_ids,'unity_boxes')\n",
    "\n",
    "# The folder where crops will be placed after running the detector\n",
    "crop_folder = path_join(postprocessing_base,'crops',base_task_name)\n",
    "\n",
    "# A detection results file in SpeciesNet format, referring to the crops, so every detection\n",
    "# has bbox [0,0,1,1]\n",
    "crop_detections_predictions_file = \\\n",
    "    insert_before_extension(detection_results_file_for_crop_folder,'speciesnet_format')\n",
    "\n",
    "# The instances.json file that refers just to the crops folder\n",
    "crop_instances_json = path_join(combined_api_output_folder,\n",
    "                                   base_task_name + '-crop_instances.json')\n",
    "\n",
    "\n",
    "## Classification constants\n",
    "\n",
    "# The instances.json file we use to pass path names and the country code to the\n",
    "# classifier and ensemble\n",
    "instances_json = \\\n",
    "    path_join(combined_api_output_folder,\n",
    "                 base_task_name + '-instances.json')\n",
    "\n",
    "# The results of the classifier (in SpeciesNet format), after running it on the crops\n",
    "classifier_output_file_modular_crops = \\\n",
    "    path_join(combined_api_output_folder,\n",
    "                 base_task_name + '-classifier_output_modular_crops.json')\n",
    "\n",
    "# The folder where we'll store classifier results for each chunk\n",
    "#\n",
    "# (...if we're breaking classification into chunks).\n",
    "chunk_folder = path_join(filename_base,'classifier_chunks')\n",
    "\n",
    "# The .sh file we'll use to launch the classifier\n",
    "classifier_script_file = path_join(filename_base,'run_all_classifier_chunks.sh')\n",
    "\n",
    "\n",
    "## Ensemble constants\n",
    "\n",
    "# The results of the ensemble, after running it on the crops (in SpeciesNet format)\n",
    "ensemble_output_file_modular_crops = \\\n",
    "    path_join(combined_api_output_folder,\n",
    "                 base_task_name + '-ensemble_output_modular_crops.json')\n",
    "\n",
    "# The results of the ensemble after running it on the crops (in MD format)\n",
    "ensemble_output_file_crops_md_format = insert_before_extension(\n",
    "    ensemble_output_file_modular_crops,\n",
    "    'md-format')\n",
    "\n",
    "# The results of the ensemble, mapped back to image level (in MD format)\n",
    "ensemble_output_file_image_level_md_format = \\\n",
    "    ensemble_output_file_crops_md_format.replace('_crops','_image-level')\n",
    "\n",
    "\n",
    "## Smoothing constants\n",
    "\n",
    "# The ensemble results (in MD format) after image-level smoothing\n",
    "classifier_output_path_within_image_smoothing = insert_before_extension(\n",
    "    ensemble_output_file_image_level_md_format,'within_image_smoothing')\n",
    "\n",
    "sequence_smoothed_classification_file = \\\n",
    "    insert_before_extension(classifier_output_path_within_image_smoothing,\n",
    "                            'seqsmoothing')\n",
    "\n",
    "custom_taxa_output_file = insert_before_extension(\n",
    "    ensemble_output_file_image_level_md_format,'custom-species-{}'.format(custom_taxa_stage))\n",
    "\n",
    "\n",
    "## Miscellaneous\n",
    "\n",
    "geofence_footer = None\n",
    "\n",
    "if filtered_output_filename is not None and os.path.isfile(filtered_output_filename):\n",
    "    print('Using filtered MD output file {} for classification'.format(filtered_output_filename))\n",
    "    detector_output_file_md_format = filtered_output_filename\n",
    "else:\n",
    "    print('It looks like you didn\\'t do RDE, using raw MD output for classification')\n",
    "    detector_output_file_md_format = combined_api_output_file\n",
    "\n",
    "assert os.path.isdir(speciesnet_model_file)\n",
    "os.makedirs(crop_folder,exist_ok=True)\n",
    "\n",
    "for fn in [classifier_output_file_modular_crops,\n",
    "           ensemble_output_file_modular_crops]:\n",
    "    if os.path.exists(fn):\n",
    "        print('**\\nWarning, file {} exists, this is OK if you are resuming\\n**\\n'.format(fn))\n",
    "\n",
    "assert country_code is not None, 'Did you mean to specify a country code?'\n",
    "if country_code == 'USA' and state_code is None:\n",
    "    print('*** Did you mean to specify a state code? ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2d986",
   "metadata": {},
   "source": [
    "## Generate instances.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...for the original images.\n",
    "\n",
    "instances = generate_instances_json_from_folder(folder=input_path,\n",
    "                                                country=country_code,\n",
    "                                                admin1_region=state_code,\n",
    "                                                output_file=instances_json,\n",
    "                                                filename_replacements=None)\n",
    "\n",
    "print('Generated {} instances'.format(len(instances['instances'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb70f9f",
   "metadata": {},
   "source": [
    "## Generate crop dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0533161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.postprocessing.create_crop_folder import \\\n",
    "    CreateCropFolderOptions, create_crop_folder\n",
    "\n",
    "create_crop_folder_options = CreateCropFolderOptions()\n",
    "create_crop_folder_options.n_workers = 8\n",
    "create_crop_folder_options.pool_type = 'process'\n",
    "if parallelization_defaults_to_threads:\n",
    "    create_crop_folder_options.pool_type = 'thread'\n",
    "\n",
    "create_crop_folder(input_file=detector_output_file_md_format,\n",
    "                   input_folder=input_path,\n",
    "                   output_folder=crop_folder,\n",
    "                   output_file=detection_results_file_with_crop_ids,\n",
    "                   crops_output_file=detection_results_file_for_crop_folder,\n",
    "                   options=create_crop_folder_options)\n",
    "\n",
    "assert os.path.isfile(detection_results_file_with_crop_ids)\n",
    "assert os.path.isfile(detection_results_file_for_crop_folder)\n",
    "assert os.path.isdir(crop_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa7e50",
   "metadata": {},
   "source": [
    "## Convert the detection results for the crops to predictions.json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02cfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the input to the ensemble when we run it on the crops.\n",
    "\n",
    "from megadetector.utils.wi_utils import generate_predictions_json_from_md_results\n",
    "\n",
    "generate_predictions_json_from_md_results(md_results_file=detection_results_file_for_crop_folder,\n",
    "                                          predictions_json_file=crop_detections_predictions_file,\n",
    "                                          base_folder=crop_folder)\n",
    "\n",
    "\n",
    "##%% Generate a new instances.json file for the crops\n",
    "\n",
    "crop_instances = generate_instances_json_from_folder(folder=crop_folder,\n",
    "                                                     country=country_code,\n",
    "                                                     admin1_region=state_code,\n",
    "                                                     output_file=crop_instances_json,\n",
    "                                                     filename_replacements=None)\n",
    "\n",
    "print('Generated {} instances for the crop folder (in file {})'.format(\n",
    "    len(crop_instances['instances']),crop_instances_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc1182",
   "metadata": {},
   "source": [
    "## Run classifier on crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c25db",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(chunk_folder,exist_ok=True)\n",
    "\n",
    "print('Reading crop instances json...')\n",
    "\n",
    "with open(crop_instances_json,'r') as f:\n",
    "    crop_instances_dict = json.load(f)\n",
    "\n",
    "crop_instances = crop_instances_dict['instances']\n",
    "\n",
    "if max_images_per_chunk is None:\n",
    "    chunks = split_list_into_n_chunks(crop_instances,n_gpus)\n",
    "else:\n",
    "    chunks = split_list_into_fixed_size_chunks(crop_instances,max_images_per_chunk)\n",
    "print('Split {} crop instances into {} chunks'.format(len(crop_instances),len(chunks)))\n",
    "\n",
    "chunk_scripts = []\n",
    "\n",
    "print('Reading detection results...')\n",
    "\n",
    "with open(crop_detections_predictions_file,'r') as f:\n",
    "    detections = json.load(f)\n",
    "\n",
    "detection_filepath_to_instance = {p['filepath']:p for p in detections['predictions']}\n",
    "\n",
    "chunk_prediction_files = []\n",
    "\n",
    "gpu_to_classifier_scripts = defaultdict(list)\n",
    "\n",
    "# i_chunk = 0; chunk = chunks[i_chunk]\n",
    "for i_chunk,chunk in enumerate(chunks):\n",
    "\n",
    "    if n_gpus > 1:\n",
    "        gpu_number = i_chunk % n_gpus\n",
    "    else:\n",
    "        gpu_number = default_gpu_number\n",
    "\n",
    "    if default_gpu_number is not None:\n",
    "        if os.name == 'nt':\n",
    "            cuda_prefix = f'set CUDA_VISIBLE_DEVICES={gpu_number} & '\n",
    "        else:\n",
    "            cuda_prefix = f'CUDA_VISIBLE_DEVICES={gpu_number} '\n",
    "    else:\n",
    "        cuda_prefix = ''\n",
    "\n",
    "    chunk_str = str(i_chunk).zfill(3)\n",
    "\n",
    "    chunk_instances_json = path_join(chunk_folder,'crop_instances_chunk_{}.json'.format(\n",
    "        chunk_str))\n",
    "    chunk_instances_dict = {'instances':chunk}\n",
    "    with open(chunk_instances_json,'w') as f:\n",
    "        json.dump(chunk_instances_dict,f,indent=1)\n",
    "\n",
    "    chunk_detections_json = path_join(chunk_folder,'detections_chunk_{}.json'.format(\n",
    "        chunk_str))\n",
    "\n",
    "    detection_predictions_this_chunk = []\n",
    "\n",
    "    images_this_chunk = [instance['filepath'] for instance in chunk]\n",
    "\n",
    "    for image_fn in images_this_chunk:\n",
    "        assert image_fn in detection_filepath_to_instance\n",
    "        detection_predictions_this_chunk.append(detection_filepath_to_instance[image_fn])\n",
    "\n",
    "    detection_predictions_dict = {'predictions':detection_predictions_this_chunk}\n",
    "\n",
    "    with open(chunk_detections_json,'w') as f:\n",
    "        json.dump(detection_predictions_dict,f,indent=1)\n",
    "\n",
    "    chunk_files = [instance['filepath'] for instance in chunk]\n",
    "\n",
    "    chunk_predictions_json = path_join(chunk_folder,'predictions_chunk_{}.json'.format(\n",
    "        chunk_str))\n",
    "\n",
    "    if os.path.isfile(chunk_predictions_json):\n",
    "        print('Warning: chunk output file {} exists'.format(chunk_predictions_json))\n",
    "\n",
    "    chunk_prediction_files.append(chunk_predictions_json)\n",
    "\n",
    "    chunk_script = path_join(chunk_folder,'run_chunk_{}{}'.format(i_chunk,script_extension))\n",
    "    cmd = 'python speciesnet/scripts/run_model.py --classifier_only --model \"{}\"'.format(\n",
    "        speciesnet_model_file)\n",
    "    cmd += ' --instances_json \"{}\"'.format(chunk_instances_json)\n",
    "    cmd += ' --predictions_json \"{}\"'.format(chunk_predictions_json)\n",
    "    cmd += ' --detections_json \"{}\"'.format(chunk_detections_json)\n",
    "\n",
    "    if classifier_batch_size is not None:\n",
    "       cmd += ' --batch_size {}'.format(classifier_batch_size)\n",
    "\n",
    "    chunk_script_file = path_join(chunk_folder,'run_chunk_{}{}'.format(chunk_str,script_extension))\n",
    "\n",
    "    with open(chunk_script_file,'w') as f:\n",
    "        # This writes, e.g. \"set -e\"\n",
    "        if script_header is not None and len(script_header) > 0:\n",
    "            f.write(script_header + '\\n')\n",
    "        f.write(cuda_prefix + cmd)\n",
    "\n",
    "    st = os.stat(chunk_script_file)\n",
    "    os.chmod(chunk_script_file, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "    gpu_to_classifier_scripts[gpu_number].append(chunk_script_file)\n",
    "\n",
    "# ...for each chunk\n",
    "\n",
    "per_gpu_scripts = []\n",
    "\n",
    "# Write out a script for each GPU that runs all of the commands associated with\n",
    "# that GPU.\n",
    "for gpu_number in gpu_to_classifier_scripts:\n",
    "\n",
    "    gpu_script_file = path_join(filename_base,'run_classifier_for_gpu_{}{}'.format(\n",
    "        str(gpu_number).zfill(2),script_extension))\n",
    "    per_gpu_scripts.append(gpu_script_file)\n",
    "\n",
    "    if os.name == 'nt':\n",
    "        prepare_conda_environment_cmd = 'call'\n",
    "    else:\n",
    "        prepare_conda_environment_cmd = 'eval \"$(conda shell.bash hook)\" && '\n",
    "\n",
    "    classifier_init_cmd = f'cd {speciesnet_folder} && {prepare_conda_environment_cmd} conda activate {speciesnet_classifier_environment_name}'\n",
    "\n",
    "    with open(gpu_script_file,'w') as f:\n",
    "\n",
    "        # This writes, e.g. \"set -e\"\n",
    "        if script_header is not None and len(script_header) > 0:\n",
    "            f.write(script_header)\n",
    "\n",
    "        # Change folder/environment\n",
    "        f.write(classifier_init_cmd + '\\n')\n",
    "\n",
    "        for script_name in gpu_to_classifier_scripts[gpu_number]:\n",
    "\n",
    "            s = script_name\n",
    "            # When calling a series of batch files on Windows from within a batch file, you need to\n",
    "            # use \"call\", or only the first will be executed.  No, it doesn't make sense.\n",
    "            if os.name == 'nt':\n",
    "                s = 'call ' + s\n",
    "            f.write(s + '\\n')\n",
    "\n",
    "        f.write('echo \"Finished all commands for GPU {}\"'.format(gpu_number))\n",
    "\n",
    "    st = os.stat(gpu_script_file)\n",
    "    os.chmod(gpu_script_file, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "# ...for each GPU\n",
    "\n",
    "print('\\nClassification scripts you should run now:')\n",
    "for s in per_gpu_scripts:\n",
    "    print(s)\n",
    "\n",
    "# import clipboard; clipboard.copy(per_gpu_scripts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370c5ee",
   "metadata": {},
   "source": [
    "## Merge crop classification result batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a776fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.utils.wi_utils import merge_prediction_json_files\n",
    "\n",
    "merge_prediction_json_files(input_prediction_files=chunk_prediction_files,\n",
    "                            output_prediction_file=classifier_output_file_modular_crops)\n",
    "\n",
    "\n",
    "##%% Validate crop classification results\n",
    "\n",
    "from megadetector.utils.wi_utils import validate_predictions_file\n",
    "_ = validate_predictions_file(classifier_output_file_modular_crops,crop_instances_json)\n",
    "\n",
    "\n",
    "##%% Run geofencing (still crops)\n",
    "\n",
    "# It doesn't matter here which environment we use, and there's no need to add the CUDA prefix\n",
    "ensemble_commands = []\n",
    "ensemble_commands.append(f'cd {speciesnet_folder} && conda activate {speciesnet_detector_environment_name}')\n",
    "\n",
    "cmd = 'python speciesnet/scripts/run_model.py --ensemble_only --model \"{}\"'.format(speciesnet_model_file)\n",
    "cmd += ' --instances_json \"{}\"'.format(crop_instances_json)\n",
    "cmd += ' --classifications_json \"{}\"'.format(classifier_output_file_modular_crops)\n",
    "cmd += ' --detections_json \"{}\"'.format(crop_detections_predictions_file)\n",
    "cmd += ' --predictions_json \"{}\"'.format(ensemble_output_file_modular_crops)\n",
    "\n",
    "# Currently we only skip the geofence if we're imminently going to apply a custom taxa\n",
    "# list, otherwise the smoothing is quite messy.\n",
    "if (custom_taxa_list is not None) and (custom_taxa_stage == 'before_smoothing'):\n",
    "    cmd += ' --nogeofence'\n",
    "\n",
    "ensemble_commands.append(cmd)\n",
    "\n",
    "ensemble_cmd = '\\n\\n'.join(ensemble_commands)\n",
    "# print(ensemble_cmd); clipboard.copy(ensemble_cmd)\n",
    "\n",
    "print('Ensemble command you should run now:\\n\\n{}'.format(ensemble_cmd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8589de7f",
   "metadata": {},
   "source": [
    "## Validate ensemble results (still crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.utils.wi_utils import validate_predictions_file\n",
    "_ = validate_predictions_file(ensemble_output_file_modular_crops,crop_instances_json)\n",
    "\n",
    "\n",
    "##%% Generate a list of corrections made by geofencing, and counts (still crops)\n",
    "\n",
    "from megadetector.utils.wi_utils import find_geofence_adjustments, \\\n",
    "    generate_geofence_adjustment_html_summary\n",
    "\n",
    "rollup_pair_to_count = find_geofence_adjustments(ensemble_output_file_modular_crops,\n",
    "                                                 use_latin_names=False)\n",
    "\n",
    "geofence_footer = generate_geofence_adjustment_html_summary(rollup_pair_to_count)\n",
    "\n",
    "\n",
    "##%% Convert output file to MD format (still crops)\n",
    "\n",
    "assert os.path.isfile(ensemble_output_file_modular_crops)\n",
    "\n",
    "generate_md_results_from_predictions_json(predictions_json_file=ensemble_output_file_modular_crops,\n",
    "                                          md_results_file=ensemble_output_file_crops_md_format,\n",
    "                                          base_folder=crop_folder+'/')\n",
    "\n",
    "# from megadetector.utils.path_utils import open_file; open_file(ensemble_output_file_md_format)\n",
    "\n",
    "\n",
    "##%% Bring those crop-level results back to image level\n",
    "\n",
    "from megadetector.postprocessing.create_crop_folder import crop_results_to_image_results\n",
    "\n",
    "assert '_crops' in ensemble_output_file_crops_md_format\n",
    "\n",
    "crop_results_to_image_results(\n",
    "    image_results_file_with_crop_ids=detection_results_file_with_crop_ids,\n",
    "    crop_results_file=ensemble_output_file_crops_md_format,\n",
    "    output_file=ensemble_output_file_image_level_md_format)\n",
    "\n",
    "assert os.path.isfile(ensemble_output_file_image_level_md_format)\n",
    "\n",
    "\n",
    "##%% Confirm that all the right images are in the classification results\n",
    "\n",
    "import json\n",
    "from megadetector.utils.path_utils import find_images\n",
    "\n",
    "with open(ensemble_output_file_image_level_md_format,'r') as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "filenames_in_results = set([im['file'] for im in d['images']])\n",
    "images_in_folder = set(find_images(input_path,recursive=True,return_relative_paths=True))\n",
    "\n",
    "for fn in filenames_in_results:\n",
    "    assert fn in images_in_folder, \\\n",
    "        'Image {} present in results but not in folder'.format(fn)\n",
    "\n",
    "for fn in images_in_folder:\n",
    "    assert fn in filenames_in_results, \\\n",
    "        'Image {} present in folder but not in results'.format(fn)\n",
    "\n",
    "n_failures = 0\n",
    "\n",
    "# im = d['images'][0]\n",
    "for im in d['images']:\n",
    "    if 'failure' in im:\n",
    "        n_failures += 1\n",
    "\n",
    "print('Loaded results for {} images with {} failures'.format(\n",
    "    len(images_in_folder),n_failures))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e574393",
   "metadata": {},
   "source": [
    "## Possibly apply a custom taxa list (before smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30724635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.postprocessing.classification_postprocessing import restrict_to_taxa_list\n",
    "\n",
    "if (custom_taxa_list is not None) and (custom_taxa_stage == 'before_smoothing'):\n",
    "\n",
    "    taxa_list = custom_taxa_list\n",
    "    speciesnet_taxonomy_file = taxonomy_file\n",
    "    restrict_to_taxa_list(taxa_list=taxa_list,\n",
    "                          speciesnet_taxonomy_file=speciesnet_taxonomy_file,\n",
    "                          input_file=ensemble_output_file_image_level_md_format,\n",
    "                          output_file=custom_taxa_output_file,\n",
    "                          allow_walk_down=custom_taxa_allow_walk_down)\n",
    "\n",
    "pre_smoothing_file = ensemble_output_file_image_level_md_format\n",
    "if os.path.isfile(custom_taxa_output_file):\n",
    "    pre_smoothing_file = custom_taxa_output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee3f05",
   "metadata": {},
   "source": [
    "## Preview (post-classification, pre-smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a869192",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_options = deepcopy(preview_options_base)\n",
    "preview_options.image_base_dir = input_path\n",
    "\n",
    "preview_folder = path_join(postprocessing_output_folder,\n",
    "    base_task_name + '_{}_classification'.format(preview_options.confidence_threshold))\n",
    "\n",
    "os.makedirs(preview_folder, exist_ok=True)\n",
    "\n",
    "preview_options.md_results_file = pre_smoothing_file\n",
    "preview_options.output_dir = preview_folder\n",
    "preview_options.footer_text = geofence_footer\n",
    "\n",
    "print('Generating post-clssification smoothing preview in {}'.format(preview_folder))\n",
    "ppresults = process_batch_results(preview_options)\n",
    "open_file(ppresults.output_html_file,attempt_to_open_in_wsl_host=True,browser_name='chrome')\n",
    "# import clipboard; clipboard.copy(ppresults.output_html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ed4aa",
   "metadata": {},
   "source": [
    "## Within-image classification smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.postprocessing.classification_postprocessing import \\\n",
    "    smooth_classification_results_image_level, \\\n",
    "    ClassificationSmoothingOptions\n",
    "\n",
    "within_image_smoothing_options = ClassificationSmoothingOptions()\n",
    "\n",
    "if allow_same_family_smoothing:\n",
    "    within_image_smoothing_options.max_detections_nondominant_class_same_family = 10000\n",
    "\n",
    "_ = smooth_classification_results_image_level(input_file=pre_smoothing_file,\n",
    "                                              output_file=classifier_output_path_within_image_smoothing,\n",
    "                                              options=within_image_smoothing_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42edc3",
   "metadata": {},
   "source": [
    "## Preview (post-within-image smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_options = deepcopy(preview_options_base)\n",
    "preview_options.image_base_dir = input_path\n",
    "\n",
    "preview_folder = path_join(postprocessing_output_folder,\n",
    "    base_task_name + '_{}_within-image-smoothing'.format(preview_options.confidence_threshold))\n",
    "\n",
    "os.makedirs(preview_folder, exist_ok=True)\n",
    "\n",
    "preview_options.md_results_file = classifier_output_path_within_image_smoothing\n",
    "preview_options.output_dir = preview_folder\n",
    "\n",
    "print('Generating post-within-image smoothing preview in {}'.format(preview_folder))\n",
    "ppresults = process_batch_results(preview_options)\n",
    "open_file(ppresults.output_html_file,attempt_to_open_in_wsl_host=True,browser_name='chrome')\n",
    "# import clipboard; clipboard.copy(ppresults.output_html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbee69",
   "metadata": {},
   "source": [
    "## Build sequences from either EXIF info or folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How should we determine sequence information?\n",
    "\n",
    "# Use 'exif' for most image (non-video) cases\n",
    "sequence_method = 'exif'\n",
    "\n",
    "# Use 'folder when leaf node folders are sequences, typically when each folder really represents\n",
    "# frames from a single video.\n",
    "# sequence_method = 'folder'\n",
    "\n",
    "\n",
    "##%% If we're building sequence information based on EXIF data\n",
    "\n",
    "if sequence_method == 'exif':\n",
    "\n",
    "    pass\n",
    "\n",
    "    ##%% Read EXIF date and time from all images\n",
    "\n",
    "    from megadetector.data_management import read_exif\n",
    "    exif_options = read_exif.ReadExifOptions()\n",
    "\n",
    "    exif_options.verbose = False\n",
    "    exif_options.n_workers = default_workers_for_parallel_tasks\n",
    "    exif_options.use_threads = parallelization_defaults_to_threads\n",
    "    exif_options.processing_library = 'pil'\n",
    "    exif_options.byte_handling = 'delete'\n",
    "    exif_options.tags_to_include = ['DateTime','DateTimeOriginal']\n",
    "\n",
    "    if os.path.isfile(exif_results_file):\n",
    "        print('Reading EXIF data from {}'.format(exif_results_file))\n",
    "        with open(exif_results_file,'r') as f:\n",
    "            exif_results = json.load(f)\n",
    "    else:\n",
    "        exif_results = read_exif.read_exif_from_folder(input_path,\n",
    "                                                       output_file=exif_results_file,\n",
    "                                                       options=exif_options)\n",
    "\n",
    "\n",
    "    ##%% Prepare COCO-camera-traps-compatible image objects for EXIF results\n",
    "\n",
    "    # ...and add location/datetime info based on filenames and EXIF information.\n",
    "\n",
    "    from megadetector.data_management.read_exif import \\\n",
    "        exif_results_to_cct, ExifResultsToCCTOptions\n",
    "    from megadetector.utils.ct_utils import is_function_name\n",
    "\n",
    "    exif_results_to_cct_options = ExifResultsToCCTOptions()\n",
    "\n",
    "    exif_data_in_cct_format_file = path_join(filename_base,'exif_data_in_cct_format.json')\n",
    "\n",
    "    if os.path.isfile(exif_data_in_cct_format_file):\n",
    "\n",
    "        print('Reading CCT-formatted EXIF data from {}'.format(exif_data_in_cct_format_file))\n",
    "\n",
    "        with open(exif_data_in_cct_format_file,'r') as f:\n",
    "            cct_dict = json.load(f)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # If we've defined a \"custom_relative_path_to_location\" location, which by convention\n",
    "        # is what we use in this notebook for a non-standard location mapping function, use it\n",
    "        # to parse locations when creating the CCT data.\n",
    "        if is_function_name('custom_relative_path_to_location',locals()):\n",
    "            print('Using custom location mapping function in EXIF conversion')\n",
    "            exif_results_to_cct_options.filename_to_location_function = \\\n",
    "                custom_relative_path_to_location # type: ignore # noqa\n",
    "\n",
    "        cct_dict = exif_results_to_cct(exif_results=exif_results,\n",
    "                                       cct_output_file=exif_data_in_cct_format_file,\n",
    "                                       options=exif_results_to_cct_options)\n",
    "\n",
    "\n",
    "    ##%% Assemble images into sequences\n",
    "\n",
    "    from megadetector.data_management import cct_json_utils\n",
    "    from megadetector.data_management.cct_json_utils import SequenceOptions\n",
    "\n",
    "    sequence_options = SequenceOptions()\n",
    "\n",
    "    print('Assembling images into sequences')\n",
    "    _ = cct_json_utils.create_sequences(cct_dict, options=sequence_options)\n",
    "\n",
    "\n",
    "##%% If we're building sequence information based on folder structure\n",
    "\n",
    "else:\n",
    "\n",
    "    assert sequence_method == 'folder'\n",
    "    pass\n",
    "\n",
    "\n",
    "    ##%% Read the list of filenames\n",
    "\n",
    "    input_file_for_sequence_aggregation = classifier_output_path_within_image_smoothing\n",
    "    with open(input_file_for_sequence_aggregation,'r') as f:\n",
    "        d = json.load(f)\n",
    "\n",
    "\n",
    "    ##%% Synthesize sequences\n",
    "\n",
    "    cct_dict = {'info':{},'annotations':[],'categories':[],'images':[]}\n",
    "\n",
    "    folder_name_to_images = defaultdict(list) # noqa\n",
    "    images_out = []\n",
    "\n",
    "    # im_in = d['images'][0]\n",
    "    for im_in in tqdm(d['images']):\n",
    "\n",
    "        folder_name = os.path.dirname(im_in['file']).replace('\\\\','/')\n",
    "        folder_name_to_images[folder_name].append(im_in['file'])\n",
    "\n",
    "        im_out = {}\n",
    "        images_out.append(im_out)\n",
    "\n",
    "        im_out['file_name'] = im_in['file']\n",
    "        im_out['seq_id'] = folder_name\n",
    "\n",
    "        # Not required for smoothing\n",
    "        # im_out['frame_num'] = len(folder_name_to_images[folder_name]) - 1\n",
    "        # location_name = os.path.dirname(folder_name).replace('\\\\','/')\n",
    "        # im_out['location'] = location_name\n",
    "\n",
    "    cct_dict['images'] = images_out\n",
    "\n",
    "    print('Extracted {} sequences from {} images'.format(\n",
    "        len(folder_name_to_images),len(d['images'])))\n",
    "\n",
    "\n",
    "##%% Sequence-level smoothing\n",
    "\n",
    "from megadetector.postprocessing.classification_postprocessing import \\\n",
    "    smooth_classification_results_sequence_level, \\\n",
    "    ClassificationSmoothingOptions\n",
    "\n",
    "input_file_for_sequence_level_smoothing = None\n",
    "if os.path.isfile(classifier_output_path_within_image_smoothing):\n",
    "    print('Using within-image smoothing results for sequence-level smoothing')\n",
    "    input_file_for_sequence_level_smoothing = \\\n",
    "        classifier_output_path_within_image_smoothing\n",
    "else:\n",
    "    assert os.path.isfile(ensemble_output_file_image_level_md_format)\n",
    "    print('Using ensemble output file for sequence-level smoothing (no image-level smoothing file found)')\n",
    "    input_file_for_sequence_level_smoothing = \\\n",
    "        ensemble_output_file_image_level_md_format\n",
    "\n",
    "sequence_level_smoothing_options = ClassificationSmoothingOptions()\n",
    "\n",
    "if allow_same_family_smoothing:\n",
    "    sequence_level_smoothing_options.max_detections_nondominant_class_same_family = 10000\n",
    "\n",
    "_ = smooth_classification_results_sequence_level(input_file=input_file_for_sequence_level_smoothing,\n",
    "                                                 cct_sequence_information=cct_dict,\n",
    "                                                 output_file=sequence_smoothed_classification_file,\n",
    "                                                 options=sequence_level_smoothing_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0c988f",
   "metadata": {},
   "source": [
    "## Preview (post-sequence-smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d2a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_options = deepcopy(preview_options_base)\n",
    "preview_options.image_base_dir = input_path\n",
    "\n",
    "preview_folder = path_join(postprocessing_output_folder,\n",
    "    base_task_name + '_{}_sequence-smoothing'.format(preview_options.confidence_threshold))\n",
    "\n",
    "os.makedirs(preview_folder, exist_ok=True)\n",
    "\n",
    "preview_options.md_results_file = sequence_smoothed_classification_file\n",
    "preview_options.output_dir = preview_folder\n",
    "preview_options.footer_text = geofence_footer\n",
    "\n",
    "print('Generating post-sequence-smoothing preview in {}'.format(preview_folder))\n",
    "ppresults = process_batch_results(preview_options)\n",
    "open_file(ppresults.output_html_file,attempt_to_open_in_wsl_host=True,browser_name='chrome')\n",
    "# import clipboard; clipboard.copy(ppresults.output_html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74320c85",
   "metadata": {},
   "source": [
    "## Possibly apply a custom taxa list (after smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0eb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.utils.wi_utils import restrict_to_taxa_list\n",
    "\n",
    "if (custom_taxa_list is not None) and (custom_taxa_stage == 'after_smoothing'):\n",
    "\n",
    "    taxa_list = custom_taxa_list\n",
    "    speciesnet_taxonomy_file = taxonomy_file\n",
    "    custom_taxa_output_file = insert_before_extension(\n",
    "        sequence_smoothed_classification_file,'custom-species')\n",
    "\n",
    "    restrict_to_taxa_list(taxa_list=taxa_list,\n",
    "                          speciesnet_taxonomy_file=speciesnet_taxonomy_file,\n",
    "                          input_file=sequence_smoothed_classification_file,\n",
    "                          output_file=custom_taxa_output_file,\n",
    "                          allow_walk_down=custom_taxa_allow_walk_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d43bd",
   "metadata": {},
   "source": [
    "## Preview (post-custom_taxa-smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa0df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (custom_taxa_list is not None) and (custom_taxa_stage == 'after_smoothing'):\n",
    "\n",
    "    preview_options = deepcopy(preview_options_base)\n",
    "    preview_options.image_base_dir = input_path\n",
    "\n",
    "    preview_folder = path_join(postprocessing_output_folder,\n",
    "        base_task_name + '_{}_custom_taxa'.format(preview_options.confidence_threshold))\n",
    "\n",
    "    os.makedirs(preview_folder, exist_ok=True)\n",
    "\n",
    "    preview_options.md_results_file = custom_taxa_output_file\n",
    "    preview_options.output_dir = preview_folder\n",
    "    preview_options.footer_text = geofence_footer\n",
    "\n",
    "    print('Generating post-sequence-smoothing preview in {}'.format(preview_folder))\n",
    "    ppresults = process_batch_results(preview_options)\n",
    "    open_file(ppresults.output_html_file,attempt_to_open_in_wsl_host=True,browser_name='chrome')\n",
    "    # import clipboard; clipboard.copy(ppresults.output_html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f3074",
   "metadata": {},
   "source": [
    "## Remove unused categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbac94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.postprocessing.subset_json_detector_output import \\\n",
    "    SubsetJsonDetectorOutputOptions, subset_json_detector_output\n",
    "\n",
    "from megadetector.postprocessing.validate_batch_results import \\\n",
    "    ValidateBatchResultsOptions, validate_batch_results\n",
    "\n",
    "input_fn_abs = sequence_smoothed_classification_file\n",
    "output_fn_abs = insert_before_extension(input_fn_abs,'trimmed')\n",
    "\n",
    "options = SubsetJsonDetectorOutputOptions()\n",
    "options.remove_classification_categories_below_count = 1\n",
    "options.overwrite_json_files = True\n",
    "_ = subset_json_detector_output(input_fn_abs, output_fn_abs, options)\n",
    "\n",
    "validation_options = ValidateBatchResultsOptions()\n",
    "validation_options.raise_errors = True\n",
    "_ = validate_batch_results(output_fn_abs, validation_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c4de0",
   "metadata": {},
   "source": [
    "## Zip .json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dce27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megadetector.utils.path_utils import parallel_zip_files\n",
    "\n",
    "json_files = os.listdir(combined_api_output_folder)\n",
    "json_files = [fn for fn in json_files if fn.endswith('.json')]\n",
    "json_files = [path_join(combined_api_output_folder,fn) for fn in json_files]\n",
    "\n",
    "parallel_zip_files(json_files,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cbe281",
   "metadata": {},
   "source": [
    "## 99.9% of jobs end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73675b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remaining cells are run often, but not all the time.\n",
    "#\n",
    "# See manage_local_batch_scrap.py for additional cells I sometimes run at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7a700",
   "metadata": {},
   "source": [
    "## .json splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "\n",
    "from megadetector.postprocessing.subset_json_detector_output import \\\n",
    "    subset_json_detector_output, SubsetJsonDetectorOutputOptions\n",
    "\n",
    "input_filename = filtered_output_filename\n",
    "output_base = path_join(combined_api_output_folder,base_task_name + '_json_subsets')\n",
    "\n",
    "print('Processing file {} to {}'.format(input_filename,output_base))\n",
    "\n",
    "options = SubsetJsonDetectorOutputOptions()\n",
    "# options.query = None\n",
    "# options.replacement = None\n",
    "\n",
    "options.split_folders = True\n",
    "options.make_folder_relative = True\n",
    "\n",
    "# Reminder: 'n_from_bottom' with a parameter of zero is the same as 'bottom'\n",
    "options.split_folder_mode = 'bottom'  # 'top', 'n_from_top', 'n_from_bottom'\n",
    "options.split_folder_param = 0\n",
    "options.overwrite_json_files = False\n",
    "options.confidence_threshold = 0.01\n",
    "\n",
    "subset_data = subset_json_detector_output(input_filename, output_base, options, data)\n",
    "\n",
    "# Zip the subsets folder\n",
    "from megadetector.utils.path_utils import zip_folder\n",
    "zip_folder(output_base,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b62da9f",
   "metadata": {},
   "source": [
    "## Custom splitting/subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25390e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "\n",
    "from megadetector.postprocessing.subset_json_detector_output import \\\n",
    "    subset_json_detector_output, SubsetJsonDetectorOutputOptions\n",
    "\n",
    "input_filename = filtered_output_filename\n",
    "output_base = path_join(filename_base,'json_subsets')\n",
    "\n",
    "folders = os.listdir(input_path)\n",
    "\n",
    "if data is None:\n",
    "    with open(input_filename) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "print('Data set contains {} images'.format(len(data['images'])))\n",
    "\n",
    "# i_folder = 0; folder_name = folders[i_folder]\n",
    "for i_folder, folder_name in enumerate(folders):\n",
    "\n",
    "    output_filename = path_join(output_base, folder_name + '.json')\n",
    "    print('Processing folder {} of {} ({}) to {}'.format(i_folder, len(folders), folder_name,\n",
    "          output_filename))\n",
    "\n",
    "    options = SubsetJsonDetectorOutputOptions()\n",
    "    options.confidence_threshold = 0.01\n",
    "    options.overwrite_json_files = True\n",
    "    options.query = folder_name + '/'\n",
    "\n",
    "    # This doesn't do anything in this case, since we're not splitting folders\n",
    "    # options.make_folder_relative = True\n",
    "\n",
    "    subset_data = subset_json_detector_output(input_filename, output_filename, options, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658dcbdf",
   "metadata": {},
   "source": [
    "## Sample custom path replacement function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_relative_path_to_location(relative_path):\n",
    "\n",
    "    relative_path = relative_path.replace('\\\\','/')\n",
    "    tokens = relative_path.split('/')\n",
    "\n",
    "    # This example uses a hypothetical (but relatively common) scheme\n",
    "    # where the first two slash-separated tokens define a site, e.g.\n",
    "    # where filenames might look like:\n",
    "    #\n",
    "    # north_fork/site001/recnyx001/image001.jpg\n",
    "    location_name = '/'.join(tokens[0:2])\n",
    "    return location_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07117747",
   "metadata": {},
   "source": [
    "## Test relative_path_to_location on the current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb98984",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(combined_api_output_file,'r') as f:\n",
    "    d = json.load(f)\n",
    "image_filenames = [im['file'] for im in d['images']]\n",
    "\n",
    "location_names = set()\n",
    "\n",
    "# relative_path = image_filenames[0]\n",
    "for relative_path in tqdm(image_filenames):\n",
    "\n",
    "    # Use the standard replacement function\n",
    "    location_name = relative_path_to_location(relative_path)\n",
    "\n",
    "    # Use a custom replacement function\n",
    "    # location_name = custom_relative_path_to_location(relative_path)\n",
    "\n",
    "    location_names.add(location_name)\n",
    "\n",
    "location_names = list(location_names)\n",
    "location_names.sort()\n",
    "\n",
    "for s in location_names:\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
